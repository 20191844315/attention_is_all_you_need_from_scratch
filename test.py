# inference.py
import torch
from model import Transformer
from dataset import cmn_words, eng_words, sos, eos, seq_len, pad, get_dataset

# ---------------------
# åŠ è½½æ¨¡å‹
# ---------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# è·å–è¯è¡¨å¤§å°
_, test_loader = get_dataset()
input_size = len(cmn_words) + eos + 1
output_size = len(eng_words) + eos + 1

# åˆå§‹åŒ–æ¨¡å‹ç»“æ„
model = Transformer(
    input_size=input_size,
    output_size=output_size,
    max_len=seq_len,
    padding_idx=pad
).to(device)

# åŠ è½½æƒé‡
model.load_state_dict(torch.load("best_model.pt", map_location=device))
model.eval()

# ---------------------
# ç¿»è¯‘å‡½æ•°
# ---------------------
@torch.no_grad()
def translate(model, src_sentence, max_len=seq_len):
    """
    src_sentence: ä¸­æ–‡è¾“å…¥åºåˆ—ï¼ˆç´¢å¼•è¡¨ç¤ºçš„tensorï¼‰
    """
    src = torch.tensor(src_sentence, dtype=torch.long, device=device).unsqueeze(0)
    y = torch.full((1, 1), sos, dtype=torch.long, device=device)

    for _ in range(max_len - 1):
        logits = model(src, y)
        next_token = logits[:, -1, :].argmax(dim=-1, keepdim=True)
        y = torch.cat([y, next_token], dim=1)
        if next_token.item() == eos:
            break

    output_indices = [i - eos - 1 for i in y.view(-1).tolist() if i > eos]
    return " ".join(eng_words[i] for i in output_indices)

# # ---------------------
# # æµ‹è¯•ï¼šä» test_loader å–ä¸€ä¸ªæ ·æœ¬
# # ---------------------
# for src, tgt in test_loader:
#     src = src[0].tolist()
#     tgt = [i - eos - 1 for i in tgt[0].tolist() if i > eos]
#
#     src_sentence = [i for i in src if i > 0]
#     output = translate(model, src_sentence)
#
#     print("source:", " ".join(cmn_words[i - eos - 1] for i in src_sentence if i > eos))
#     print("target:", " ".join(eng_words[i] for i in tgt))
#     print("output:", output)
#     break  # åªæ¼”ç¤ºä¸€ä¸ªæ ·æœ¬
# ---------------------
# ç”¨æˆ·è¾“å…¥äº¤äº’æ¨¡å¼
# ---------------------
print("\nğŸš€ Transformer ç¿»è¯‘å™¨å·²åŠ è½½ï¼")
print("è¾“å…¥ä¸­æ–‡è¯è¯­ï¼ˆä»¥ç©ºæ ¼åˆ†éš”ï¼‰ï¼Œæˆ‘å°†å°è¯•è¾“å‡ºè‹±æ–‡ç¿»è¯‘ã€‚")
print("è¾“å…¥ q é€€å‡ºã€‚\n")

while True:
    sentence = input("ä½ : ").strip()
    if sentence.lower() == "q":
        print("å†è§ ğŸ‘‹")
        break

    # åˆ†è¯åŒ¹é…ï¼ˆå‡è®¾ cmn_words æ˜¯ä¸€ä¸ª listï¼‰
    tokens = sentence.split()
    src_indices = []
    for w in tokens:
        if w in cmn_words:
            src_indices.append(cmn_words.index(w) + eos + 1)
        else:
            print(f"âš ï¸ æœªçŸ¥è¯ï¼š{w}")
            continue

    if not src_indices:
        continue

    output = translate(model, src_indices)
    print("ğŸ—£ï¸ è‹±æ–‡è¾“å‡º:", output)
    print()